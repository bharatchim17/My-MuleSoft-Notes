--------------------------------------------------------------------------------------
//Kafka: 
Is written in scala & java Apache Kafka is an open-source distributed-streaming & 
messaging system Originally designed by LinkedIn with capabilities to handle huge 
loads of data with its distrubuted , fault tolerence architecture it works with 
pub-sub mechanism for message communication..
database have high storage but low throughput that's why , Operation Per Second is low..
Whereas kafka has high throughput and low storage...


//What is message..?  is small to medium size piece of data:

1. Producer: is an application that sends data to kafka server...
2. Consumer: an application that receive data from kafka sever..
3. Broker: is kafka server
4. Cluster: group of computers
5. Topic: is unique name for kafka stream..
6. Partitions: part of topic 
7. Offset: unique , sequence id for message within partition..
8. Consumer groups: group of consumers acting as single logic unit..

E:\Mule-Soft\Message-Broker\kafka-3.7.0-src\bin\windows add this path in environment 
variable...
kafka-3.7.0-src\bin\windows <--- type cmd in this path

//Error Occure:
Classpath is empty. Please build the project first e.g. by running 'gradlew jarAll'
Solution: https://medium.com/@praveenkumarsingh/confluent-kafka-on-windows-how-to-fix-classpath-is-empty-cf7c31d9c787

//wmic' is not recognized as an internal or external command,
operable program or batch file.
Solution: 

---------------------------------------------------------------------------------------
//kafka random commands:

zookeeper-server-start.bat ..\..\config\zookeeper.properties
zookeeper-server-start.bat <----add path of zookeeper.properties

kafka-server-start.bat ..\..\config\server.properties
kafka-server-start.bat .<----add path of server.properties

kafka-topics.bat --create --topic my-topic --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3

kafka-console-producer.bat --broker-list localhost:9092 --topic my-topic

kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic my-topic --from-beginning
----------------------------------------------------------------------------------------------------
//Create data folder in path: kafka-3.7.0-src
In data floder create folder: broker & zookeeper
1. zookeeper: 
In config zookeeper.properties dataDir = paste path with forward slash (/) of zookeeper folder 
2. broker: 
In config server.properties  log.dirs= paste path with forward slash (/) here of broker folder 

                               ------- or -------

1. In config zookeeper.properties dataDir = log.dirs=C:/kafka/zookeeper-data

2. In config server.properties  log.dirs= log.dirs=C:/kafka/zookeeper-data


---------------------------------------------------------------------------------
//kafka Operations:
1. Batch message listener (source)
2. Message listener (source)
3. Consume
4. Commit 
5. Publish
---------------------------------------------------------------------------------
1. Batch message listener: 
This source supports the consumption of messages from a Kafka Cluster, producing a 
List of messages to the flow...
#General:
Poll timeout:
Poll timeout time unit: Days | Hours | Second
Acknowledgement mode: Auto | Dups_Ok | Empty | Immediate | Manual
Amount of parallel consumer: 

2. Message listener:
This source supports the consumption of messages from a Kafka Cluster, producing a 
single message to the flow...

#Global Element
Topic subcription patterns: Edit inline ✅ + | Bean Reference | None
Topic patern:
value: Topic_Name
----------------------------------------------------------------------------------
3. Consume:
This operation allows receiving messages from one or more Kafka topics, it works very 
similarly to the Message Listener source, so all the operations that apply to that, 
will apply to this operation as well.
Note: The consume operation works only in IMMEDIATE mode. The consume operation does 
not return the consumerCommitKey...
#General:
Consumption timeout:
Timeout Time Unit:
Acknowledgement mode:
--------------------------------------------------------------------------------
4. Commit:
Commits the offsets associated to a message or batch of messages consumed in a 
Message Listener. This would be a List or a single message consumed in the 
BatchMessageListenerSource..
#General:
Consumer commit key:
-----------------------------------------------------------------------------------
5. Publish:
Publish a message to the specified kafka topic, optionally specifying the partition, 
key and message content for it. The publish operation supports transactions..
#General:
Topic: Topic_Name
Partion:
Key: #[now()]
Message: #[payload] (default) | "We can put message here"
Headers: 

#Global Element
Bootstrap server: Edit inline ✅ + | Bean Reference
Bootstrap server
Value : localhost:9092
-------------------------------------------------------------------------------
6. Seek:
Sets the current offset value for the given topic, partition and consumer group of 
the listener..
#General:
Topic:
Partion:
Offset:
------------------------------------------------------------------------------------
